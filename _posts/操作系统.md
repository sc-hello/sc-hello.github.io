@[TOC](目录)
# 1 什么是操作系统+1
1. 本质是运行在计算机上的软件，管理计算机硬件和软件；
2. 为用户提供一个与系统交互的操作界面；
3. 分内核与外壳（内核是能操作硬件的程序，外壳是围绕着内核的应用程序）；
4. 内核负责管理系统的进程、内存、设备驱动程序、文件和网络系统等，决定着系统的性能和稳定性，是连接应用程序和硬件的桥梁；

# 2 什么是系统调用+1
1. 根据进程访问资源的特点，可以把进程在系统上的运行分为两个级别：（1用户态：用户态运行的进程可以访问用户程序的数据 2系统态：系统态运行的进程几乎可以访问计算机上所有的资源）；
2. 进程基本都是运行在用户态，但如果需要调用系统态级别的功能（设备管理、文件管理、内存管理、进程控制、进程通信），就必须通过系统调用的方式向操作系统提出服务请求，并由操作系统代为完成；
3. 系统调用的功能有如下几类（1 设备管理：完成设备的启动、请求、释放等功能；2 文件管理：完成文件的读、写、创建、删除等功能；3 内存管理：完成内存的分配、回收及获取作业占用内存区大小及地址等功能；4 进程控制：完成进程的创建、撤销、阻塞、唤醒等功能；5 进程通信：完成进程之间的消息传递等功能；）

# 3 进程和线程的区别+1
1. **拥有资源**：进程是资源分配的基本单位，但线程不拥有资源，线程可以访问隶属于进程的资源；
2. **调度**：线程是独立调度的基本单位，同一进程中，线程的切换不会引起进程切换；但从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换；
3. **系统开销**：创建或撤销进程时，系统要为之分配或回收资源，如内存空间、I/O设备等，所付出的开销远大于创建或撤销线程时的开销；类似地，在进行进程切换时，涉及当前执行进程CPU环境的保存及新调度进程CPU环境的设置，占用很多开销，而线程切换只需保存和设置少量寄存器内容，开销很小；
4. **通信方面**：线程之间可以通过直接读写同一进程中的数据进行通信，但进程之间的通信需要借助IPC；

# 4 从 JVM 的角度来说一下进程和线程之间的关系+1
1. 线程是进程划分成的更小的运行单位，一个进程在执行过程中可以产生多个线程；多个线程共享进程的堆和方法区，每个线程有自己的程序计数器、虚拟机栈和本地方法栈；
2. 各进程相互独立，而同一进程中的线程极有可能互相影响；
3. 线程执行开销小，但不利于资源的管理和保护，进程则相反；

# 5 进程有哪几种状态？+1
5种状态。

1. **新建状态(New)**：进程被创建，但未到就绪状态；
2. **就绪状态(Ready)**：进程已处于准备运行状态，获得了除CPU之外的一切所需资源，一旦得到CPU分配的时间片即可运行；
3. **运行状态(Running)**：进程正在CPU上运行；
4. **阻塞状态(Waiting)**：进程正在等待某一事件而暂停执行如等待某资源为可用或等待IO操作完成；
5. **结束状态(Terminated)**：进程正在从系统中消失，可能是进程正常结束或其他原因中断退出；

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210508150234658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NjMTc5,size_16,color_FFFFFF,t_70)

# 6 进程间有哪几种常见的通信方式？+1
7种。

1. **匿名管道（Pipes）**：用于具有亲缘关系的父子进程间或兄弟进程间的通信；
2. **有名管道（Names Pipes）**：1 有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信；2 有名管道严格遵循FIFO（先进先出）；
3. **信号（Signal）**：是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
4. **消息队列（Message Queuing）**：1 是消息的链表，存放在内核中并由消息队列标识符标识；2 消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可以按消息的类型读取，比FIFO更有优势；3 消息队列克服了信号承载信息量少、管道只能承载无格式字节流以及缓冲区大小受限等缺点；
5. **信号量（Semaphores）**：是一个计数器，用于多线程对共享数据的访问，意图在于进程间同步，主要用于解决与同步相关的问题并避免竞争条件；
6. **共享内存（Shared memory）**：1 使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新；2 需要依靠某种同步操作，如互斥锁和信号量等；3 可以说是最有用的进程间通信方式；
7. **套接字（Sockets）**：1 主要用于在客户端和服务器之间通过网络进行通信，是支持TCP/IP的网络通信的基本操作单元 2 可以看作不同主机之间的进程进行双向通信的端点 3 用套接字中的相关函数来完成通信过程；

# 7 线程间的同步方式有哪几种？+1
1. **互斥量（Mutex）**：1 采用互斥对象机制，只有拥有互斥对象的线程才有权限访问公共资源 2 由于互斥对象只有一个，因此可以避免公共资源被多个线程同时访问 3 Java中的sychronized关键字和各种Lock都是这种机制；
2. **信号量（Semaphore）**：1 允许同一时刻多个线程访问同一资源 2 但需要控制同一时刻访问此资源的最大线程数量；
3. **事件（Event）**：1 利用通知操作的方式来实现多线程同步 2 还可以方便地实现多线程的优先级比较 3 比如Java中的Wait/Notify就是这种机制；


# 11 同步与互斥+1
 - 同步：多个进程按一定顺序执行；
 - 互斥：多个进程在同一时刻只能有一个进程进入临界区；

（同步是一种更为复杂的互斥。互斥是指多个进程不可以同时运行，但并不限制任务的运行顺序，而同步也是不能同时运行，但必须要按照某种次序来运行。）

# 12 操作系统中进程的调度算法有哪些？+1
不同环境的调度算法目标不同，因此需要针对不同环境来讨论。

**1 批处理系统**

批处理系统没有太多的用户操作，在该系统中，调度算法的目标是保证吞吐量和周转时间（从提交到终止的时间）。

1. **先来先服务（FCFS）**：1.1 按照请求的顺序进行调度；1.2 有利于长作业，不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长；
2. **短作业优先（SJF）**：2.1 按估计运行时间最短的顺序进行调度；2.2 长作业有可能会饿死，处于一直等待短作业执行完毕的状态，因为如果一直有短作业到来，长作业永远得不到调度；
3. **最短剩余时间优先（SRTN）**：按估计剩余时间最短的顺序进行调度；

**2 交互式系统**

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

1. **时间片轮转**：1.1 将所有就绪进程按FCFS的原则排成一个队列，每次调度时，把CPU时间分配给队首进程，该进程可以执行一个时间片；1.2 当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并把它送往就绪队列的末尾，同时继续把CPU时间分配给队首的进程；1.3 时间片轮转算法的效率和时间片的大小有很大关系：如果时间片太小，会导致进程切换太频繁，在进程切换上会花费过多时间（进程切换要保存进程信息并载入新进程信息）；如果时间片太大，实时性就不能得到保证；
2. **优先级调度**：2.1 为每个进程分配一个优先级，按优先级进行调度；2.2 为了防止低优先级的进程永远得不到调度，可以随着时间的推移增加等待进程的优先级；
3. **多级反馈队列**：3.1 一个进程需要执行100个时间片，如果采用时间片轮转调度算法，需要交换100次；3.2 多级反馈队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不相同，例如1，2，4，8...。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换7次；3.3 每个队列优先权也不同，最上面的优先权最高，因此只有上一个队列没有进程在排队，才能调度当前队列上的进程；3.4 可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合；

**3 实时系统**

1. 实时系统要求一个请求在一个确定时间内得到响应；
2. 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时；

# 11 操作系统的内存管理主要是做什么？+1
1. 内存的分配与回收（malloc函数：申请内存；free函数：释放内存）；
2. 地址转换工作：将逻辑地址转换成相应的物理地址；

# 12 操作系统有哪几种内存管理机制？+1
0. 1 分连续分配管理和非连续分配管理这两种。2 连续分配管理方式是指为一个程序分配一个连续的内存空间，如块式管理；3 非连续分配管理方式是指为一个程序分配的内存可以是离散的或者说是不相邻的，如页式管理、段式管理、段页式管理；
1. **块式管理**：1 原始计算机系统的内存管理方式。2 将主存划分为几个固定大小的块，每个块中只包含一个进程；3 如果程序运行需要内存的话，操作系统就分配给它一块；4 如果程序运行只需要很小的内存的话，分配的这块内存很大一部分就被浪费了；5 这些在每个块中未被利用的内存称之为碎片；
2. **页式管理**：1 把主存划分为大小相等且固定的一页一页的形式，页较小，相比于块式管理划分力度更大，提高了内存利用率，减少了碎片；2 页式管理通过页表对应逻辑地址和物理地址；
3. **段式管理**：1 页式管理虽然提高了内存利用率，但页式管理中的页并无任何实际意义。2 段式管理把主存分为一段一段的形式，段有实际意义，每个段定义了一组逻辑信息，例如有主程序段MAIN、子程序段X、数据段D及栈段S等；3 段式管理通过段表对应逻辑地址和物理地址；
4. **段页式管理**：1 段页式结合了段式和页式的优点。2 把主存先分成若干段，每个段有分成若干页，即段与段之间以及段的内部都是离散的；

# 13 分页机制和分段机制的共同点和区别？+1
**1 共同点**

1. 都是为了减少内存碎片，提高内存利用率；
2. 页和段都是离散存储的，但每个页和每个段中的内存是连续的；

**2 区别**

1. 页的大小固定，由操作系统决定；而段的大小不固定，由运行的应用程序决定；
2. 分页仅仅是为了满足操作系统内存管理的需求；而段是逻辑信息的单位，在程序中可以体现为代码段、数据段，能更好地满足用户需求；

# 14 页表管理机制中有两个很重要的概念：快表和多级页表，它们分别解决了页表管理中很重要的两个问题，请叙述。+1
0. 在分页内存管理中，很重要的两点是：1 虚拟地址到物理地址的转换要快；2 解决虚拟地址空间大，页表也会很大的问题；
1. **快表**：1.1 为了提高虚拟地址到物理地址的转换速度，引入了快表；1.2 可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的部分或全部内容；1.3作为页表的Cache，它的作用与页表相似，但是提高了访问速率；1.4 由于采用页表做地址转换，读写内存数据时CPU要访问两次主存，有了快表，有时只要访问一次高速缓冲存储器、一次主存，这样就可加速查找并提高指令执行速度；1.5 使用快表之后的地址转换流程如下（1 根据虚拟地址中的页号查快表；2 如果该页在快表中，直接从快表中读取相应的物理地址；3 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；4 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页）；
2. **多级页表**：引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景，具体可以参考: [多级页表如何节约内存](https://www.polarxiong.com/archives/%E5%A4%9A%E7%BA%A7%E9%A1%B5%E8%A1%A8%E5%A6%82%E4%BD%95%E8%8A%82%E7%BA%A6%E5%86%85%E5%AD%98.html).
3. **总结**：为了提高内存的空间性能，提出了多级页表的概念，但是却牺牲了时间性能；为了弥补损失的时间性能，提出了快表的概念。不管是快表还是多级页表实际上都利用了程序的局部性原理。

# 18 程序的局部性原理+1
1. 程序的局部性原理是指程序在执行时呈现出局部性规律，又可分为：时间局部性和空间局部性；
3. 时间局部性是指如果程序中的某条指令一旦执行，则不久之后该指令可能再次被执行；空间局部性是指一旦程序访问了某个存储单元，则不久之后，其附近的存储单元也将被访问；
4. 虚拟内存技术实际上就是建立了 “内存⼀外存”的两级存储器结构，利用局部性原理实现髙速缓存；

# 15 逻辑地址和物理地址+1
1. **逻辑地址**：逻辑地址由操作系统决定，和编程打交道的一般都是逻辑地址。比如在C语言中，指针里存储的数值就是内存里的一个逻辑地址；
2. **物理地址**：即真实物理内存中的地址，更具体一点来说就是内存地址寄存器中的地址；

# 16 CPU寻址是什么？为什么需要虚拟地址空间？+1
1. **CPU寻址**：CPU需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。完成虚拟地址转换为物理地址任务的是CPU中一个被称为内存管理单元（Memory Management Unit, MMU）的硬件。

2. **为什么要有虚拟地址空间**？1 如果没有虚拟地址空间，程序直接访问和操作的都是物理内存。就会带来两个问题：1.1 用户程序可以访问任意内存，这样很容易破坏操作系统，造成操作系统崩溃；1.2 想要同时运行多个程序特别困难。比如想同时运行一个微信和一个QQ都不行。因为当微信在运行时给内存地址1XXX赋值后，QQ也可能同样给内存地址1XXX赋值，那么QQ对内存的赋值就会覆盖微信之前的赋值，如此就造成了微信程序的崩溃。2 而通过虚拟地址访问内存有以下优势：2.1 程序可以使用⼀系列相邻的虚拟地址来访问物理内存中不相邻的内存缓冲区；2.2 程序可以使用⼀系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将内存页保存到磁盘文件，在需要时进行数据交换；2.3 不同进程使用的虚拟地址彼此隔离，因此⼀个进程无法访问正在由另⼀进程访问的物理内存；

# 17 虚拟内存+1
1. 虚拟内存是计算机系统内存管理的一种技术，它使得应用程序认为它拥有连续可用的内存，而实际上它通常被分割成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换；
2.  为了更好的管理内存，操作系统将内存抽象成地址空间；
3. 虚拟内存能让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存；
4. 每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页；
5. 这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中；当程序引用的页不在物理内存中时，由操作系统按照页面置换算法将对应的页调入物理内存，并重新执行失败的指令；
6. 虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能；
7. 例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32K 的物理内存，虚拟内存技术允许该计算机运行一个 64K 的程序；

# 19 虚拟存储器+1
1. 基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分放在外存，就可以启动程序运行；
2. 当访问的内容不在内存中时，由操作系统将所需要的内容调入内存，然后继续执行程序。同时，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的内容；
3. 这样，计算机好像为用户提供了一个比实际内存大得多的存储器——虚拟存储器；

# 20 虚拟内存技术的实现+1
虚拟内存技术的实现需要建立在离散分配的内存管理方式的基础上，有以下三种实现方式：

1  **请求分页式存储管理**：

1. 建立在分页存储管理之上，增加了请求调页和页面置换功能；
2. 请求分页是最常用的实现虚拟存储器的方法；
3. 在作业开始运行前，仅装入当前要执行的部分页即可运行；
4. 如果在执行过程中发现要访问的页不在内存，则由操作系统按照对应的页面置换算法将对应的页调入内存，同时将暂时不用的页置换到外存；

2 **请求分段式存储管理**

1. 建立在分段存储管理之上，增加了请求调段和分段置换功能；
2. 在作业开始运行之前，仅装入当前要执行的部分段即可运行；
3. 如果在执行过程中发现要访问的段不在内存，则使用请求调入中断来动态装入对应的段，同时按照分段置换算法将暂时不用的段置换到外存；

3 **请求段页式存储管理**


# 21 请求分页存储管理与分页存储管理的不同？+1

1. 请求分页存储管理建立在分页存储管理之上；
2. 请求分页存储管理不要求将作业全部地址空间同时装入主存，而分页存储管理要求。基于这一点，请求分页存储管理可以提供虚拟内存，而分页存储管理不可以；

# 22 页面置换算法+1
**0 背景**

1. 在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中；
2. 此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间；
3. 页面置换算法的主要目标是使页面置换频率最低（即缺页率最低）；

**1 OPT(Optimal,最佳）**

1. 被换出的页面将是最长时间内不再被访问的页面，可以保证获得最低的缺页率；
2. 是一种理论上的算法，因为无法知道一个页面多长时间不再被访问，因此该算法无法实现，一般用来衡量其他置换算法；

**2 LRU(Least Recently Used,最近最少使用)**

1. 将最近最少的页面换出；
2. 为了实现LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头，这样就能保证链表表尾的页面是最近最少使用的；
3. 由于每次访问都需要更新链表，因此这种方式实现的代价很高；

**3 NRU(Not Recently Used,最近未使用)**

1. 每个页面都有两个状态位：R与M，当页面被访问时设置R=1，当页面被修改时设置M=1。其中R位会定时被清0；
2. 可以将页面分成四类：1 R=0，M=0；2 R=0，M=1；3 R=1，M=0；4 R=1，M=1；
3. 当发生缺页中断时，NRU随机从类编号最小的非空类中挑选一个页面将它换出；
4. NRU优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁访问的干净页面（R=1，M=0）；

**4 FIFO(First In First Out,先进先出)**

1. 选择换出的页面是最先进入的页面；
2. 可能将那些经常被访问的页面也被换出，从而使缺页率升高；

**5 第二次机会算法**

1. FIFO算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一些优化；
2. 当页面被访问（读或写）时设置该页面的R位为1；
3. 需要替换时，检查最老页面的R位，如果R位是0，说明这个页面既老又没有被使用，可以立刻置换掉；
4. 如果R位是1，则将R位清0，并把该页面放到链表的尾端，修改它的装入时间就像它刚装入一样，然后继续从链表头部开始搜索；

**6 时钟算法**

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，使用一个指针指向最老的页面。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210527215920600.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NjMTc5,size_16,color_FFFFFF,t_70)

# 23 死锁概念及本质原因+1
**概念**：多个并发进程因争夺系统资源而产生互相等待的现象；

**本质原因**：

1. 系统资源有限；
2. 进程推进顺序不合理；

# 24 死锁产生的必要条件+1

 1. **互斥**：某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束；
 2. **占有和等待**：一个进程本身占有资源，同时还有一些资源未得到满足，正在等待其他进程释放这些资源；
 3. **不可抢占**：已经分配给一个进程的资源不能被强制性地抢占，它只能被占有它的进程显式地释放；
 4. **循环等待**：存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源；

# 25 死锁的处理方法+1

 1. 鸵鸟策略；
 2. 死锁检测与死锁恢复（不阻止，发生时恢复）；
 3. 死锁预防（运行前）；
 4. 死锁避免（运行时）；

# 26 鸵鸟策略+1
 1. 把头埋进沙子里，假装没发生问题，即不采取任何措施；
 2. 由于处理死锁的代价很高，因此鸵鸟策略会获得更高的性能；
 3. 当死锁不会对用户造成很大影响、或者发生死锁的概率很低时，可以采用鸵鸟策略；
 4. 大多数操作系统，包括 Unix、Linux 和 Windows，处理死锁都采用鸵鸟策略，然后手动干预（重新启动）；

# 27 死锁检测与死锁恢复（不阻止，发生时恢复）+1
不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

1. **每种类型一个资源的死锁检测**：1 每种类型一个资源的死锁检测算法通过检测有向图是否存在环来实现；2 依次从每一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到了死锁的发生；
2. **每种类型多个资源的死锁检测**： 1 E 向量：资源总量；A 向量：资源剩余量；C 矩阵：每个进程所拥有的资源数量；R 矩阵：每个进程请求的资源数量；2 每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程；3 3.1寻找一个没有被标记的进程 Pi，它所请求的资源R[i]小于等于 A；3.2 如果找到了这样一个进程，那么将它拥有的资源C[i]加到 A 中，并标记该进程，同时转回上一步；3.3如果没有这样一个进程，算法终止；如果最后所有进程都被标记，则没有死锁，否则有死锁；
3. **死锁恢复**： 1 通过抢占恢复；2 通过回滚恢复；3 通过杀死进程恢复；

# 28 死锁预防（运行前）+1
在程序**运行前**预防死锁。

1. **破坏互斥**：例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。
2. **破坏占有和等待**：1 **方法1**：所有进程在开始运行前，必须一次性申请其在整个运行过程中所需要的全部资源。 优点：简单易实施且安全； 缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，造成资源浪费，使进程经常发生饥饿现象；2 **方法2**：对第一种方法的改进，允许进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放已经使用完毕的资源，再去请求新的资源。这样的话，资源的利用率会得到提高，也会减少进程的饥饿现象。
3. **破坏不可抢占**：1. 当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请，这就意味着进程已占有的资源被抢占了；2. 这种方法实现比较复杂，代价也比较大。释放已经保持的资源很可能会导致进程之前的工作失效，也可能导致进程的执行被无限推迟；
4. **破坏循环等待**：给资源统一编号，进程只能按编号顺序来请求资源。当一个进程拥有编号为 i 的资源时，那么它下一次只能申请编号大于 i 的资源；

# 29 死锁避免（运行时）+1
在程序**运行时**避免死锁。

1. **安全状态**：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也依然存在某种调度次序能够使得每一个进程执行完毕，那么该状态是安全的；
2. **单个资源的银行家算法**：1 检查是否有足够的额度满足某一客户，如果有，那么这笔贷款就是能够收回的，并将此客户的贷款加入可用额度里，接着检查能够满足的另一个客户，以此类推；2 如果最终所有贷款都能被收回，那么该状态就是安全的（满足该请求），否则不安全（推迟该请求）；
3. **多个资源的银行家算法**： 1 检查还需分配资源的矩阵是否存在一行小于等于可用资源的向量。如果不存在这样的行，那么系统将发生死锁，状态是不安全的；2 假若找到这样一行，标记该进程，并将其已分配资源加到可用资源的向量中；3 重复以上两步，如果最终所有进程都被标记，则状态是安全的（满足该请求），否则不安全（推迟该请求）；

# 30 磁盘调度算法+1
0. 读写一个磁盘块的时间影响因素有：1 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）；2 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）；3 实际的数据传输时间。其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。
1. **先来先服务**：1 按照磁盘请求的顺序进行调度；2 优点是公平和简单；3 缺点也很明显，因为未对寻道做任何优化，因此平均寻道时间可能较长；
2. **最短寻道时间优先**：1 优先调度与当前磁头所在磁道距离最近的磁道；2 虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现了饥饿现象，尤其是两端的磁道请求更容易出现饥饿现象；
3. **电梯算法**：1 电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向； 2 电梯算法和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向；3 由于考虑了移动方向，因此所有的磁盘请求都会被满足，解决了饥饿问题；
